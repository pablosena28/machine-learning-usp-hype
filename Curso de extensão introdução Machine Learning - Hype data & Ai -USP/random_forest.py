# -*- coding: utf-8 -*-
"""Random Forest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16egLGyFK68yCO7gp8gnXaAh1XMFFd6xI
"""

# Modelo de Random Forest com Cross Validation e teste de melhor Hiperparâmetro

# ------------------------------------------------------------
# 1. Importando as bibliotecas necessárias
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, f1_score
from sklearn.datasets import load_wine

# ------------------------------------------------------------
# 2. Carregando o dataset Wine
data = load_wine()
X = data['data']       # Atributos (características dos vinhos)
y = data['target']     # Classes (tipos de vinho)

# ------------------------------------------------------------
# 3. Dividindo os dados em treino e teste (70% treino, 30% teste)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# ------------------------------------------------------------
# 4. Definindo o grid de hiperparâmetros para busca
param_grid = {
    'n_estimators': [50, 100, 200],         # Número de árvores
    'max_depth': [None, 10],                # Profundidade máxima
    'max_samples': [0.5, None],             # Proporção de amostras por árvore
    'min_samples_split': [2, 5],            # Mínimo de amostras para dividir um nó
    'min_samples_leaf': [1, 2],             # Mínimo de amostras em uma folha
    'max_features': ['sqrt'],               # Número de atributos por divisão
    'bootstrap': [True]                     # Amostragem com reposição
}

# ------------------------------------------------------------
# 5. Criando o modelo para busca de hiperparâmetros
rf_grid = RandomForestClassifier(random_state=42)

# ------------------------------------------------------------
# 6. Aplicando Grid Search com validação cruzada
grid_search = GridSearchCV(
    estimator=rf_grid,
    param_grid=param_grid,
    cv=5,                         # Número de folds
    scoring='f1_macro',           # Métrica de avaliação
    return_train_score=True,      # Retorna também o score de treino
    n_jobs=-1,                    # Usa todos os núcleos disponíveis
    verbose=1                     # Mostra progresso
)

# ------------------------------------------------------------
# 7. Executando o treino para a busca dos melhores hiperparâmetros
grid_search.fit(X_train, y_train)

# ------------------------------------------------------------
# 8. Exibindo os melhores hiperparâmetros encontrados
print("\n Melhores hiperparâmetros encontrados:")
print(grid_search.best_params_)
print(f"Melhor F1-Score médio na validação cruzada: {grid_search.best_score_:.4f}")

# ------------------------------------------------------------
#  9. Avaliação final no conjunto de teste
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)

print("\n Relatório de Classificação no Teste:")
print(classification_report(y_test, y_pred))
print("F1-Score no Teste (macro):", f1_score(y_test, y_pred, average='macro'))