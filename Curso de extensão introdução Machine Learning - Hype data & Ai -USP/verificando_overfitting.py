# -*- coding: utf-8 -*-
"""Verificando Overfitting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16egLGyFK68yCO7gp8gnXaAh1XMFFd6xI
"""

# VERIFICANDO OVERFITTING

# ------------------------------------------------------------
# Obtendo os resultados completos do Grid Search
# O objeto 'grid_search.cv_results_' contém todas as métricas de cada combinação testada
results = pd.DataFrame(grid_search.cv_results_)

# ------------------------------------------------------------
# Extraindo os scores de treino e validação para o melhor modelo
# 'best_index_' aponta para a linha com os melhores hiperparâmetros encontrados
best_index = grid_search.best_index_
train_score = results['mean_train_score'][best_index]   # Média do F1-score no treino
valid_score = results['mean_test_score'][best_index]    # Média do F1-score na validação

# ------------------------------------------------------------
# Exibindo os resultados
print(f"F1-score médio no treino: {train_score:.4f}")
print(f"F1-score médio na validação: {valid_score:.4f}")
print(f"Diferença (treino - validação): {train_score - valid_score:.4f}")

# ------------------------------------------------------------
# Verificando se há overfitting
# Se a diferença entre treino e validação for muito grande (> 0.05), pode indicar que o modelo está se ajustando demais aos dados de treino
if train_score - valid_score > 0.05:
    print("Possível overfitting detectado (diferença > 0.05)")
else:
    print("Modelo bem ajustado: Sem sinais significativos de overfitting")