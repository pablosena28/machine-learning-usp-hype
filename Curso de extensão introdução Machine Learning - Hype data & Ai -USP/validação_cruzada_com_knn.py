# -*- coding: utf-8 -*-
"""Validação Cruzada com KNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16egLGyFK68yCO7gp8gnXaAh1XMFFd6xI
"""

# Validação Cruzada com KNN

# A Validação Cruzada (Cross-Validation) é uma técnica usada para avaliar o desempenho de um modelo de forma mais robusta.
# Em vez de fazer uma única divisão dos dados (treino e teste), ela divide os dados em várias partes (folds),
# treina e testa o modelo múltiplas vezes em diferentes combinações desses folds e calcula a média dos resultados.

# Isso evita que a performance do modelo seja superestimada ou subestimada por sorte,
# devido a uma divisão de dados favorável ou desfavorável.

# Neste exemplo, usamos a validação cruzada para encontrar o melhor valor de 'K' para o algoritmo KNN.

# ------------------------------------------------------------

# Importação das bibliotecas necessárias
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, cross_validate
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import f1_score

#  1. Carregamento dos dados
# Usaremos o dataset Iris como exemplo
data = load_iris()
X = data.data       # Features
y = data.target     # Rótulos

# 2. Divisão dos dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 3. Lista de valores possíveis para K
k_list = [3, 5, 7, 9, 13, 17]  # Testaremos cada um com validação cruzada

# 4. Loop para testar cada valor de K
for k in k_list:
    #  Validação cruzada com 10 folds
    knn_results = cross_validate(
        KNeighborsClassifier(n_neighbors=k),  # modelo KNN com valor atual de K
        X_train,                              # dados de treino
        y_train,                              # rótulos de treino
        cv=10,                                # número de folds
        scoring=['f1_macro'],                 # métrica de avaliação
        return_train_score=True               # retorna também a pontuação no treino
    )

    #  Exibe a média das métricas de treino e validação
    print("K:", k,
          "| Train F1:", knn_results['train_f1_macro'].mean(),
          "| Validation F1:", knn_results['test_f1_macro'].mean())

    #  Treina o modelo com o valor atual de K e testa nos dados finais
    clf = KNeighborsClassifier(n_neighbors=k)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)

    #  Exibe a métrica final no conjunto de teste
    print("Test F1:", f1_score(y_test, y_pred, average='macro'))
    print()

# ------------------------------------------------------------

# O valor de K com maior F1 médio na validação cruzada é considerado o mais confiável.
# Ele foi testado em múltiplas "rodadas" e não depende de uma única divisão dos dados.